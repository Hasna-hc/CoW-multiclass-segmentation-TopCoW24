{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "conda update -n base conda &&\n",
    "conda install -n base conda-libmamba-solver &&\n",
    "conda config --set solver libmamba &&\n",
    "source ~/anaconda3/bin/activate\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "conda create -n nnunet_topcow2024 python==3.9.13 anaconda -y\n",
    "conda activate nnunet_topcow2024\n",
    "conda update -n nnunet_topcow2024 conda -y\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "conda create -n nnunet_topcow24 python==3.9.13 anaconda -y\n",
    "conda activate nnunet_topcow24\n",
    "conda update -n nnunet_topcow24 conda -y\n",
    "\n",
    "### MODIFIED THIS FILE : /home/hasna/miniconda3/envs/nnunet_topcow24/lib/python3.9/site-packages/acvl_utils/cropping_and_padding/bounding_boxes.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# pip install -r requirements.txt\n",
    "pip install -r /home/hasna/nnUNet_dir/requirements.txt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "pip install threadpoolctl==3.1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "export PYTHONPATH=\"${PYTHONPATH}:/home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Preparing nnUNet*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Installation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Following instructions from:\n",
    "https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/installation_instructions.md\n",
    "pip install -e . \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Dataset format*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob \n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from collections import OrderedDict\n",
    "from scipy.ndimage import find_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1 - CoW Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:52<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Binary MRA segmentation using MRA only '''\n",
    "\n",
    "dataset_name = 'Dataset802_TopCoWSegBinMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_mr_'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data = 1*(data>0)\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:29<00:00,  2.78it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Binary CTA segmentation using CTA only '''\n",
    "\n",
    "dataset_name = 'Dataset809_TopCoWSegBinCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_ct_'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data = 1*(data>0)\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:18<00:00,  3.18it/s] \n"
     ]
    }
   ],
   "source": [
    "''' Binary MRA segmentation using MRA only '''\n",
    "\n",
    "dataset_name = 'Dataset810_TopCoWSegBinMRAnew'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_mr_'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data = 1*(data>0)\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [05:33<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "''' CTA and MRA for multiclass seg in the final version !!! '''\n",
    "\n",
    "dataset_name = 'Dataset806_TopCoWSegCTAMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.endswith('.nii.gz'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data[data==15] = 13\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:49<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "''' CTA and MRA for multiclass seg in the final version !!! '''\n",
    "\n",
    "dataset_name = 'Dataset816_TopCoWSegMRACTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.endswith('.nii.gz'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data[data==15] = 13\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:57<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Binary CTA with CTAMRA training '''\n",
    "\n",
    "dataset_name = 'Dataset807_TopCoWSegBinCTAMRA' #'Dataset703_TopCoWDetCTAextendedMask' #'Dataset701_TopCoWDetCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.endswith('.nii.gz'):\n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data = 1*(data>0)\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:55<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Binary CTAMRA training (general) '''\n",
    "\n",
    "dataset_name = 'Dataset811_TopCoWSegBinMRACTA' #'Dataset703_TopCoWDetCTAextendedMask' #'Dataset701_TopCoWDetCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.endswith('.nii.gz'):\n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data = 1*(data>0)\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:07<00:00,  3.69it/s] \n"
     ]
    }
   ],
   "source": [
    "''' Multiclass MRA only '''\n",
    "\n",
    "dataset_name = 'Dataset808_TopCoWSegMRA' #'Dataset703_TopCoWDetCTAextendedMask' #'Dataset701_TopCoWDetCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_mr_'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data[data==15] = 13\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:15<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Multiclass MRA only '''\n",
    "\n",
    "dataset_name = 'Dataset818_TopCoWSegMRAablation' #'Dataset703_TopCoWDetCTAextendedMask' #'Dataset701_TopCoWDetCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_mr_'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data[data==15] = 13\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:30<00:00,  8.24it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Multiclass CTA only '''\n",
    "\n",
    "dataset_name = 'Dataset815_TopCoWSegCTA' #'Dataset703_TopCoWDetCTAextendedMask' #'Dataset701_TopCoWDetCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_ct_'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data[data==15] = 13\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2 - CoW Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_bounding_box_3d(mask):\n",
    "    \"\"\"\n",
    "    Given a 3D binary mask, returns the bounding box size and location in the format:\n",
    "    (size_x, size_y, size_z), (min_x, min_y, min_z)\n",
    "    \"\"\"\n",
    "    slices = find_objects(mask)\n",
    "    if slices and slices[0] is not None:\n",
    "        min_x, min_y, min_z = slices[0][0].start, slices[0][1].start, slices[0][2].start\n",
    "        max_x, max_y, max_z = slices[0][0].stop, slices[0][1].stop, slices[0][2].stop\n",
    "        return min_x, max_x, min_y, max_y, min_z, max_z\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Extend in the low part:\n",
    "def extend_mask(seg_mask, roi_mask):\n",
    "    seg_min_x, seg_max_x, seg_min_y, seg_max_y, seg_min_z, seg_max_z = get_bounding_box_3d(seg_mask)\n",
    "    roi_min_x, roi_max_x, roi_min_y, roi_max_y, roi_min_z, roi_max_z = get_bounding_box_3d(roi_mask)\n",
    "\n",
    "    if roi_min_x < seg_min_x:\n",
    "        seg_mask[roi_min_x:seg_min_x, :, :] = np.repeat(seg_mask[seg_min_x:seg_min_x+1, :, :], seg_min_x - roi_min_x, axis=0)\n",
    "    if roi_min_y < seg_min_y:\n",
    "        seg_mask[:, roi_min_y:seg_min_y, :] = np.repeat(seg_mask[:, seg_min_y:seg_min_y+1, :], seg_min_y - roi_min_y, axis=1)\n",
    "    if roi_min_z < seg_min_z:\n",
    "        seg_mask[:, :, roi_min_z:seg_min_z] = np.repeat(seg_mask[:, :, seg_min_z:seg_min_z+1], seg_min_z - roi_min_z, axis=2)\n",
    "\n",
    "    # Extend in the high part:\n",
    "    if roi_max_x > seg_max_x:\n",
    "        seg_mask[seg_max_x:roi_max_x, :, :] = np.repeat(seg_mask[seg_max_x-1:seg_max_x, :, :], roi_max_x - seg_max_x, axis=0)\n",
    "    if roi_max_y > seg_max_y:\n",
    "        seg_mask[:, seg_max_y:roi_max_y, :] = np.repeat(seg_mask[:, seg_max_y-1:seg_max_y, :], roi_max_y - seg_max_y, axis=1)\n",
    "    if roi_max_z > seg_max_z:\n",
    "        seg_mask[:, :, seg_max_z:roi_max_z] = np.repeat(seg_mask[:, :, seg_max_z-1:seg_max_z], roi_max_z - seg_max_z, axis=2)\n",
    "\n",
    "    return seg_mask\n",
    "\n",
    "\n",
    "# print(seg_min_x, seg_max_x, seg_min_y, seg_max_y, seg_min_z, seg_max_z)\n",
    "# print(roi_min_x, roi_max_x, roi_min_y, roi_max_y, roi_min_z, roi_max_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [07:24<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "''' MRA Box task with MRA only '''\n",
    "\n",
    "dataset_name = 'Dataset704_TopCoWDetMRAextendedMask'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_mr_'):  #FIXME: 'topcow_ct_'            \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # shutil.copy(init_name, new_name)\n",
    "\n",
    "        bbox_image = nib.load(os.path.join(data_folder, 'roi_masks', sub)).get_fdata().astype(np.uint8)\n",
    "        nifti_image = nib.load(os.path.join(data_folder, 'cow_seg_labelsTr', sub))\n",
    "        binary_image = (nifti_image.get_fdata() > 0).astype(int)\n",
    "        cropped_mask = binary_image*bbox_image\n",
    "\n",
    "        extended_mask = extend_mask(cropped_mask, bbox_image)\n",
    "        # nib.save(nib.Nifti1Image(extended_mask.astype('int32'), affine=nifti_image.affine), os.path.join(data_path, subfold[1], sub))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CTA Box task with CTA + MRA '''\n",
    "\n",
    "dataset_name = 'Dataset705_TopCoWDetCTAextendedMaskCTAMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "cta_imgs = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/Dataset703_TopCoWDetCTACropExtendedMulSegMask/imagesTr'\n",
    "cta_labs = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/Dataset703_TopCoWDetCTACropExtendedMulSegMask/labelsTr'\n",
    "mra_imgs = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/Dataset704_TopCoWDetMRAextendedMask/imagesTr'\n",
    "mra_labs = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/Dataset704_TopCoWDetMRAextendedMask/labelsTr'\n",
    "\n",
    "for file in tqdm(natsorted(os.listdir(cta_labs))):\n",
    "    init_name = os.path.join(cta_imgs, file.split('.')[0]+'_0000.nii.gz')\n",
    "    new_name = os.path.join(train_image_dir, file.split('.')[0]+'_0000.nii.gz')\n",
    "    # # shutil.copy(init_name, new_name)\n",
    "\n",
    "    init_name = os.path.join(cta_labs, file)\n",
    "    new_name = os.path.join(train_label_dir, file)\n",
    "    # # shutil.copy(init_name, new_name)\n",
    "\n",
    "\n",
    "for file in tqdm(natsorted(os.listdir(mra_labs))):\n",
    "    init_name = os.path.join(mra_imgs, file.split('.')[0]+'_0000.nii.gz')\n",
    "    new_name = os.path.join(train_image_dir, file.split('.')[0]+'_0000.nii.gz')\n",
    "    # # shutil.copy(init_name, new_name)\n",
    "\n",
    "    init_name = os.path.join(mra_labs, file)\n",
    "    new_name = os.path.join(train_label_dir, file)\n",
    "    # # shutil.copy(init_name, new_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Preparing dataset.json file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'Dataset705_TopCoWDetCTAextendedMaskCTAMRA' #'Dataset704_TopCoWDetMRAextendedMask'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Multiclass CoW roi Detection task using CTA but trained on CTA+MRA and bin label mask cropped from the multiclass GT and extended to have ROI bbox, trained for 5 folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"ctamra\",\n",
    "        # \"1\": \"binmask\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"cow\" : 1,\n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "### CLEANED TOPCOW_CHALLENGE FOLDER AGAIN #3\n",
    "\n",
    "dataset_name = 'Dataset806_TopCoWSegCTAMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Multiclass CoW segmentation task for CTA using CTA+MRA, trained for all folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"ctamra\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"BA\" : 1,\n",
    "        \"R-PCA\" : 2,\n",
    "        \"L-PCA\" : 3,\n",
    "        \"R-ICA\" : 4,\n",
    "        \"R-MCA\" : 5,\n",
    "        \"L-ICA\" : 6,\n",
    "        \"L-MCA\" : 7,\n",
    "        \"R-Pcom\" : 8,\n",
    "        \"L-Pcom\" : 9,\n",
    "        \"Acom\" : 10,\n",
    "        \"R-ACA\" : 11,\n",
    "        \"L-ACA\" : 12,\n",
    "        \"3rd-A2\" : 13\n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "### CLEANED TOPCOW_CHALLENGE FOLDER AGAIN #3\n",
    "\n",
    "dataset_name = 'Dataset816_TopCoWSegMRACTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Multiclass CoW segmentation task using CTA+MRA, trained for all folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"ctamra\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"BA\" : 1,\n",
    "        \"R-PCA\" : 2,\n",
    "        \"L-PCA\" : 3,\n",
    "        \"R-ICA\" : 4,\n",
    "        \"R-MCA\" : 5,\n",
    "        \"L-ICA\" : 6,\n",
    "        \"L-MCA\" : 7,\n",
    "        \"R-Pcom\" : 8,\n",
    "        \"L-Pcom\" : 9,\n",
    "        \"Acom\" : 10,\n",
    "        \"R-ACA\" : 11,\n",
    "        \"L-ACA\" : 12,\n",
    "        \"3rd-A2\" : 13\n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "### CLEANED TOPCOW_CHALLENGE FOLDER AGAIN #3\n",
    "\n",
    "dataset_name = 'Dataset807_TopCoWSegBinCTAMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Binary CoW segmentation task for CTA using CTA+MRA, trained for all folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"ctamra\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"cow\" : 1        \n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "### Binary CTAMRA training, w ith default configs\n",
    "\n",
    "dataset_name = 'Dataset811_TopCoWSegBinMRACTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Binary CoW segmentation task using CTA+MRA (general), trained for all folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"ctamra\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"cow\" : 1        \n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "### CLEANED TOPCOW_CHALLENGE FOLDER AGAIN #3\n",
    "\n",
    "dataset_name = 'Dataset808_TopCoWSegMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Multiclass CoW segmentation task for MRA, trained on 5 folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"mra\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"BA\" : 1,\n",
    "        \"R-PCA\" : 2,\n",
    "        \"L-PCA\" : 3,\n",
    "        \"R-ICA\" : 4,\n",
    "        \"R-MCA\" : 5,\n",
    "        \"L-ICA\" : 6,\n",
    "        \"L-MCA\" : 7,\n",
    "        \"R-Pcom\" : 8,\n",
    "        \"L-Pcom\" : 9,\n",
    "        \"Acom\" : 10,\n",
    "        \"R-ACA\" : 11,\n",
    "        \"L-ACA\" : 12,\n",
    "        \"3rd-A2\" : 13\n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "### CLEANED TOPCOW_CHALLENGE FOLDER AGAIN #3\n",
    "\n",
    "dataset_name = 'Dataset818_TopCoWSegMRAablation'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Multiclass CoW segmentation task for MRA, trained on 5 folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"mra\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"BA\" : 1,\n",
    "        \"R-PCA\" : 2,\n",
    "        \"L-PCA\" : 3,\n",
    "        \"R-ICA\" : 4,\n",
    "        \"R-MCA\" : 5,\n",
    "        \"L-ICA\" : 6,\n",
    "        \"L-MCA\" : 7,\n",
    "        \"R-Pcom\" : 8,\n",
    "        \"L-Pcom\" : 9,\n",
    "        \"Acom\" : 10,\n",
    "        \"R-ACA\" : 11,\n",
    "        \"L-ACA\" : 12,\n",
    "        \"3rd-A2\" : 13\n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "### Multiclass segmentation using CTA only (from scratch)\n",
    "\n",
    "dataset_name = 'Dataset815_TopCoWSegCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Multiclass CoW segmentation task for CTA, trained on 5 folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"cta\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"BA\" : 1,\n",
    "        \"R-PCA\" : 2,\n",
    "        \"L-PCA\" : 3,\n",
    "        \"R-ICA\" : 4,\n",
    "        \"R-MCA\" : 5,\n",
    "        \"L-ICA\" : 6,\n",
    "        \"L-MCA\" : 7,\n",
    "        \"R-Pcom\" : 8,\n",
    "        \"L-Pcom\" : 9,\n",
    "        \"Acom\" : 10,\n",
    "        \"R-ACA\" : 11,\n",
    "        \"L-ACA\" : 12,\n",
    "        \"3rd-A2\" : 13\n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "### Binary CTA only\n",
    "\n",
    "dataset_name = 'Dataset809_TopCoWSegBinCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Binary CoW segmentation task for CTA using CTA only, trained for all folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"cta\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"cow\" : 1        \n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "### Binary MRA only\n",
    "\n",
    "dataset_name = 'Dataset810_TopCoWSegBinMRAnew'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Binary CoW segmentation task for MRA using MRA only, trained for all folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"mra\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"cow\" : 1        \n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:22<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Information about Spacings and Sizes of all modalities '''\n",
    "\n",
    "dataset_name = 'Dataset701_TopCoWDetCTA' \n",
    "# Renaming according to nnUNet: \n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "subfold = ['imagesTr', 'cow_seg_labelsTr']\n",
    "\n",
    "mri_spacing, seg_spacing = [], []\n",
    "mri_size, seg_size = [], []\n",
    "labels = []\n",
    "fnames = []\n",
    "\n",
    "# imageTr:\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.endswith('.nii.gz'):        \n",
    "        mri = sitk.ReadImage(os.path.join(data_folder, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\"))\n",
    "        mri_spacing.append(mri.GetSpacing())\n",
    "        mri_size.append(mri.GetSize())\n",
    "        \n",
    "        seg = sitk.ReadImage(os.path.join(data_folder, subfold[1], sub))\n",
    "        seg_spacing.append(seg.GetSpacing())\n",
    "        seg_size.append(seg.GetSize())\n",
    "\n",
    "        fnames.append(sub.split('.')[0])\n",
    "        labels.append(sitk.GetArrayFromImage(seg).max())\n",
    "\n",
    "df = pd.DataFrame({'filename':fnames, 'mri_spacing':mri_spacing, 'seg_spacing':seg_spacing, 'mri_size':mri_size, 'seg_size':seg_size, 'max_label':labels})\n",
    "# df.to_csv('/home/hasna/miccai24_challenges/topcow_challenge/topcow24_dataset_spacing_size.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:18<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Information about Spacings and Sizes of all modalities '''\n",
    "\n",
    "data_folder = '/home/hasna/datasets/crown_20_mr_01062023'\n",
    "\n",
    "mri_spacing, seg_spacing = [], []\n",
    "mri_size, seg_size = [], []\n",
    "labels = []\n",
    "fnames = []\n",
    "\n",
    "# imageTr:\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'mul_labelsTr')))):\n",
    "    if sub.startswith('crown_mr_whole'):        \n",
    "        mri = sitk.ReadImage(os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\"))\n",
    "        mri_spacing.append(mri.GetSpacing())\n",
    "        mri_size.append(mri.GetSize())\n",
    "        \n",
    "        seg = sitk.ReadImage(os.path.join(data_folder, 'mul_labelsTr', sub))\n",
    "        seg_spacing.append(seg.GetSpacing())\n",
    "        seg_size.append(seg.GetSize())\n",
    "\n",
    "        fnames.append(sub.split('.')[0])\n",
    "        labels.append(sitk.GetArrayFromImage(seg).max())\n",
    "\n",
    "df = pd.DataFrame({'filename':fnames, 'mri_spacing':mri_spacing, 'seg_spacing':seg_spacing, 'mri_size':mri_size, 'seg_size':seg_size, 'max_label':labels})\n",
    "# df.to_csv('/home/hasna/miccai24_challenges/topcow_challenge/crown23_dataset_spacing_size.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Training nnUNet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nexport nnUNet_raw='/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/dataset/nnUNet_raw'\\nexport nnUNet_preprocessed='/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/dataset/preprocessed'\\nexport nnUNet_results='/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/datasetnnUNet_trained_models'\\n\\n\\n>>> For task 1:\\nnnUNetv2_extract_fingerprint -d 802 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 802 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 802 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\\nnnUNetv2_extract_fingerprint -d 806 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 806 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 806 -c 3d_fullres_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\\nnnUNetv2_extract_fingerprint -d 807 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 807 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 807 -c 3d_fullres_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\\nnnUNetv2_extract_fingerprint -d 808 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 808 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 808 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\\n\\n>>> For task 2:\\nnnUNetv2_extract_fingerprint -d 704 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 704 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 704 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\\nnnUNetv2_extract_fingerprint -d 705 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 705 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 705 -c 3d_fullres_spacing_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "export nnUNet_raw='/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw'\n",
    "export nnUNet_preprocessed='/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/preprocessed'\n",
    "export nnUNet_results='/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/datasetnnUNet_trained_models'\n",
    "\n",
    "\n",
    ">>> For task 1:\n",
    "nnUNetv2_extract_fingerprint -d 802 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 802 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 802 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 806 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 806 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 806 -c 3d_fullres_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 807 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 807 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 807 -c 3d_fullres_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 808 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 808 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 808 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 809 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 809 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 809 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 810 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 810 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 810 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 811 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 811 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 811 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 815 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 815 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 815 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 816 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 816 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 816 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 818 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 818 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 818 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "\n",
    "\n",
    ">>> For task 2:\n",
    "nnUNetv2_extract_fingerprint -d 704 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 704 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 704 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 705 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 705 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 705 -c 3d_fullres_spacing_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "export nnUNet_raw='/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/dataset/nnUNet_raw'\n",
    "export nnUNet_preprocessed='/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/dataset/preprocessed'\n",
    "export nnUNet_results='/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/datasetnnUNet_trained_models'\n",
    "'''\n",
    "\n",
    "''' For task 2: -------------------------------------------------------------------------------------------\n",
    ">>> Finetuning 704:  MAKE SURE THE SPLIT HAS NO DATA LEAKAGE\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 704 3d_fullres 0 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset102_Binseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 704 3d_fullres 1 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset102_Binseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_1/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 704 3d_fullres 2 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset102_Binseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_2/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 704 3d_fullres 3 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset102_Binseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_3/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 704 3d_fullres 4 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset102_Binseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_4/checkpoint_best.pth\n",
    "\n",
    ">>> Training 704:  3folds\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 704 3d_fullres 0 -tr nnUNetTrainerSkeletonRecall\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 704 3d_fullres 1 -tr nnUNetTrainerSkeletonRecall\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 704 3d_fullres 2 -tr nnUNetTrainerSkeletonRecall\n",
    "\n",
    "\n",
    ">>> Finetuning 705:  MAKE SURE THE SPLIT HAS NO DATA LEAKAGE\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 705 3d_fullres_spacing_ps 0 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir/dataset/preprocessed/Dataset702_TopCoWDetCTACroppedMulSegMask/pretrained_checkpoints/checkpoint_best_fold0.pth\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 705 3d_fullres_spacing_ps 1 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir/dataset/preprocessed/Dataset702_TopCoWDetCTACroppedMulSegMask/pretrained_checkpoints/checkpoint_best_fold1.pth\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 705 3d_fullres_spacing_ps 2 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir/dataset/preprocessed/Dataset702_TopCoWDetCTACroppedMulSegMask/pretrained_checkpoints/checkpoint_best_fold2.pth\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 705 3d_fullres_spacing_ps 3 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir/dataset/preprocessed/Dataset702_TopCoWDetCTACroppedMulSegMask/pretrained_checkpoints/checkpoint_best_fold3.pth\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 705 3d_fullres_spacing_ps 4 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir/dataset/preprocessed/Dataset702_TopCoWDetCTACroppedMulSegMask/pretrained_checkpoints/checkpoint_best_fold4.pth\n",
    "'''\n",
    "\n",
    "''' For task 1: -------------------------------------------------------------------------------------------\n",
    ">>> [CTA with CTAMRA] !!RETRAINED without mirror!!  Training 806 from scratch, with BinaryDice loss: \n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 806 3d_fullres_ps 0 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 806 3d_fullres_ps 1 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 806 3d_fullres_ps 2 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 806 3d_fullres_ps 3 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 806 3d_fullres_ps 4 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 807 3d_fullres_ps all -tr nnUNetTrainerSkeletonRecall\n",
    "\n",
    "\n",
    ">>> [MRA] !!RETRAINED without mirror!!  Training 808 from scratch, with BinaryDice loss: \n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 808 3d_fullres 0 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset101_Mulseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 808 3d_fullres 1 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset101_Mulseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_1/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 808 3d_fullres 2 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset101_Mulseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_2/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 808 3d_fullres 3 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset101_Mulseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_3/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 808 3d_fullres 4 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset101_Mulseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_4/checkpoint_best.pth\n",
    "\n",
    "\n",
    "\n",
    "[BINARY RETRAINING]: ------------------------------------------------------------------------------\n",
    ">>> Binary segmentation using CTA only\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 809 3d_fullres all -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "# TODO: A REFAIRE FOR 500 ONLY.. (it was correct.. just need 500)\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 809 3d_fullres 0 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 809 3d_fullres 1 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 809 3d_fullres 2 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 809 3d_fullres 3 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 809 3d_fullres 4 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "\n",
    "\n",
    ">>> Binary segmentation using MRA only\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 810 3d_fullres all -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "# TODO: A REFAIRE\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 810 3d_fullres 0 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 810 3d_fullres 1 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 810 3d_fullres 2 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "#REDO # CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 810 3d_fullres 3 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 810 3d_fullres 4 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "\n",
    ">>> Binary segmentation using CTA + MRA\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 811 3d_fullres all -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "# TODO: A REFAIRE\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 811 3d_fullres 0 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 811 3d_fullres 1 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 811 3d_fullres 2 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 811 3d_fullres 3 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 811 3d_fullres 4 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "## CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 811 3d_fullres 4 -tr nnUNetTrainerSkeletonRecall --val_best --c\n",
    "\n",
    "[MULTICLASS RETRAINING]: ----------------------------------------------------------------------------------\n",
    ">>> [CTA] !!RETRAINED without mirror!!  Training 815 from scratch, with BinaryDice loss: \n",
    "# TODO: A REFAIRE FOR SOME OF THEM TO HAVE 500 !!\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 815 3d_fullres 0 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "# CUDA_VISIBLE_DEVICES= nnUNetv2_train 815 3d_fullres 1 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 815 3d_fullres 2 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 815 3d_fullres 3 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "# CUDA_VISIBLE_DEVICES= nnUNetv2_train 815 3d_fullres 4 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "\n",
    "\n",
    ">>> [CTAMRA] !!RETRAINED without mirror!!  Training 816 from scratch, with BinaryDice loss: \n",
    "# TODO: A REFAIRE\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 816 3d_fullres 0 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 816 3d_fullres 1 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 816 3d_fullres 2 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 816 3d_fullres 3 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 816 3d_fullres 4 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "\n",
    "\n",
    "\n",
    "# FIXME: later\n",
    ">>> [MRA] !!RETRAINED without mirror!!  Training 808 with default loss: \n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 0 -tr nnUNetTrainerNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 1 -tr nnUNetTrainerNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 2 -tr nnUNetTrainerNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 3 -tr nnUNetTrainerNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 4 -tr nnUNetTrainerNoMirroring --val_best\n",
    "\n",
    ">>> [MRA] !!RETRAINED without mirror!!  Training 808 with default + SR losses: # TODO: Check the weights for the losses !!\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 808 3d_fullres 0 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 1 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 2 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 3 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 4 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "\n",
    ">>> [MRA] !!RETRAINED without mirror!!  Training 808 with default + SR + BinDice losses: \n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 808 3d_fullres 0 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best --c\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 1 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 808 3d_fullres 2 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best --c\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 3 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES= nnUNetv2_train 808 3d_fullres 4 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">>> [MRA] !!RETRAINED without mirror!!  Training 818 with default + SR + BinDice losses: \n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 818 3d_fullres 0 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 818 3d_fullres 1 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 818 3d_fullres 2 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 818 3d_fullres 3 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 818 3d_fullres 4 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best\n",
    "\n",
    ">>> [MRA] !!RETRAINED without mirror!!  Training 818 with default + SR losses: # TODO: Check the weights for the losses !!\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 818 3d_fullres 0 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 818 3d_fullres 1 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 818 3d_fullres 2 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 818 3d_fullres 3 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 818 3d_fullres 4 -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "\n",
    ">>> [MRA] !!RETRAINED without mirror!!  Training 818 with default loss: \n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 818 3d_fullres 0 -tr nnUNetTrainerNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 818 3d_fullres 1 -tr nnUNetTrainerNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 818 3d_fullres 2 -tr nnUNetTrainerNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 818 3d_fullres 3 -tr nnUNetTrainerNoMirroring --val_best\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 818 3d_fullres 4 -tr nnUNetTrainerNoMirroring --val_best\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 809 3d_fullres  -tr nnUNetTrainerSkeletonRecall --val_best --c  # Done\n",
    "## CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 810 3d_fullres  -tr nnUNetTrainerSkeletonRecall --val_best --c  # Done\n",
    "## CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 811 3d_fullres  -tr nnUNetTrainerSkeletonRecall --val_best --c  # Done\n",
    "## CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 815 3d_fullres  -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best --c  # Done\n",
    "## CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 816 3d_fullres  -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best --c  # Done\n",
    "## CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 818 3d_fullres 3 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring --val_best --c\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cd /home/hasna/miccai24_challenges/TopCoW_Algo_Submission/task-2-box   #/task-1-seg\n",
    "\n",
    "bash test_run.sh\n",
    "bash save.sh\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 3633.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nREPLACE NUMBER IN HERE: \\n/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CROWN 2023 Dataset (20 MRA)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "pred_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/predictions'\n",
    "save_gt_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/ground-truth'\n",
    "save_roi_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/roi-metadata'\n",
    "\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "os.makedirs(save_gt_folder, exist_ok=True)\n",
    "os.makedirs(save_roi_folder, exist_ok=True)\n",
    "\n",
    "seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge_final/evals/mra_crown23_skr_bindice_nomir_4folds/without_pp'\n",
    "gt_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/CROWN23/mul_labelsTr'\n",
    "roi_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/CROWN23/roi_size_loc'\n",
    "\n",
    "for file in tqdm(natsorted(os.listdir(seg_folder))):\n",
    "    if file.endswith('.nii.gz'):\n",
    "        init_name = os.path.join(seg_folder, file)\n",
    "        new_name = os.path.join(pred_folder, file.split('_0000')[0]+'.nii.gz')\n",
    "        shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(gt_folder, file.split('_0000')[0]+'.nii.gz')\n",
    "        new_name = os.path.join(save_gt_folder, file.split('_0000')[0]+'.nii.gz')\n",
    "        # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(roi_folder, file.replace(\"whole\", \"roi\").split('_0000')[0]+'.txt')\n",
    "        new_name = os.path.join(save_roi_folder, file.split('_0000')[0]+'.txt')\n",
    "        # shutil.copy(init_name, new_name)\n",
    "\n",
    "\n",
    "'''\n",
    "REPLACE NUMBER IN HERE: \n",
    "/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 524.61it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 553.58it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 545.41it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 629.21it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 743.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nREPLACE NUMBER IN HERE: \\n/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MRA 2024 Dataset (125 MRA)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "pred_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/predictions'\n",
    "save_gt_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/ground-truth'\n",
    "save_roi_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/roi-metadata'\n",
    "\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "os.makedirs(save_gt_folder, exist_ok=True)\n",
    "os.makedirs(save_roi_folder, exist_ok=True)\n",
    "\n",
    "seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge_final/evals/mra_skr_bindice_nomir_5folds/with_pp_20'\n",
    "gt_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/cow_seg_labelsTr'\n",
    "roi_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/roi_loc_labelsTr'\n",
    "nfolds = 5\n",
    "\n",
    "for i in range(nfolds):\n",
    "    for file in tqdm(natsorted(os.listdir(os.path.join(seg_folder, f'fold_{i}')))):\n",
    "        if file.endswith('.nii.gz'):\n",
    "            init_name = os.path.join(seg_folder, f'fold_{i}', file)\n",
    "            new_name = os.path.join(pred_folder, file)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(gt_folder, file)\n",
    "            new_name = os.path.join(save_gt_folder, file)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(roi_folder, file.split('.')[0]+'.txt')\n",
    "            new_name = os.path.join(save_roi_folder, file.split('.')[0]+'.txt')\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "\n",
    "'''\n",
    "REPLACE NUMBER IN HERE: \n",
    "/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MRA 2024 Dataset (125 MRA) BINARY\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "pred_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/predictions'\n",
    "save_gt_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/ground-truth'\n",
    "save_roi_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/roi-metadata'\n",
    "\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "os.makedirs(save_gt_folder, exist_ok=True)\n",
    "os.makedirs(save_roi_folder, exist_ok=True)\n",
    "\n",
    "# seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/evals/cta_skr_bindice_nomir_5folds/bin'\n",
    "seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/evals/mra_skr_bindice_nomir_5folds_ctamra/without_pp'  # mra_skr_bindice_nomir_5folds_binary_ctamra/bin\n",
    "gt_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/cow_seg_labelsTr'\n",
    "roi_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/roi_loc_labelsTr'\n",
    "nfolds = 5  #FIXME: 5 for MRA, and 1 for CTA\n",
    "\n",
    "for i in range(nfolds):\n",
    "    for file in tqdm(natsorted(os.listdir(os.path.join(seg_folder, f'fold_{i}')))):  #FIXME: For MRA\n",
    "    # # for file in tqdm(natsorted(os.listdir(os.path.join(seg_folder)))):  #FIXME: For CTA\n",
    "        if file.endswith('.nii.gz'):\n",
    "            # # file = file.split('_0000')[0]+'.nii.gz'  #FIXME: For CTA\n",
    "            init_name = os.path.join(seg_folder, f'fold_{i}', file)  #FIXME: For MRA\n",
    "            # # init_name = os.path.join(seg_folder, file.split('.')[0]+'_0000.nii.gz')  #FIXME: For CTA\n",
    "            new_name = os.path.join(pred_folder, file)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(gt_folder, file)\n",
    "            # # img = nib.load(init_name)\n",
    "            # # arr = 1*(img.get_fdata() > 0)\n",
    "            new_name = os.path.join(save_gt_folder, file)\n",
    "            # # nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(roi_folder, file.split('.')[0]+'.txt')\n",
    "            new_name = os.path.join(save_roi_folder, file.split('.')[0]+'.txt')\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "\n",
    "'''\n",
    "REPLACE NUMBER IN HERE: \n",
    "/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/126 [00:00<?, ?it/s]/tmp/ipykernel_3166620/1835575168.py:32: FutureWarning: Image data has type int64, which may cause incompatibilities with other tools. This will error in NiBabel 5.0. This warning can be silenced by passing the dtype argument to Nifti1Image().\n",
      "  nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
      "100%|██████████| 126/126 [03:24<00:00,  1.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nREPLACE NUMBER IN HERE: \\n/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MRA 2024 Dataset (125 MRA) BINARY from New Training\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "pred_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/predictions'\n",
    "save_gt_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/ground-truth'\n",
    "save_roi_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/roi-metadata'\n",
    "\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "os.makedirs(save_gt_folder, exist_ok=True)\n",
    "os.makedirs(save_roi_folder, exist_ok=True)\n",
    "\n",
    "seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/datasetnnUNet_trained_models/Dataset810_TopCoWSegBinMRAnew/nnUNetTrainerSkeletonRecall__nnUNetPlans__3d_fullres/fold_all/validation'\n",
    "gt_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/cow_seg_labelsTr'\n",
    "roi_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/roi_loc_labelsTr'\n",
    "nfolds = 1\n",
    "\n",
    "for file in tqdm(natsorted(os.listdir(os.path.join(seg_folder)))):\n",
    "    if file.startswith('topcow_mr_'):\n",
    "        init_name = os.path.join(seg_folder, file)\n",
    "        new_name = os.path.join(pred_folder, file)\n",
    "        # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(gt_folder, file)\n",
    "        img = nib.load(init_name)\n",
    "        arr = 1*(img.get_fdata() > 0)\n",
    "        new_name = os.path.join(save_gt_folder, file)\n",
    "        # nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(roi_folder, file.split('.')[0]+'.txt')\n",
    "        new_name = os.path.join(save_roi_folder, file.split('.')[0]+'.txt')\n",
    "        # shutil.copy(init_name, new_name)\n",
    "\n",
    "\n",
    "'''\n",
    "REPLACE NUMBER IN HERE: \n",
    "/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:30<00:00,  1.17s/it]\n",
      "100%|██████████| 26/26 [00:30<00:00,  1.16s/it]\n",
      "100%|██████████| 26/26 [00:34<00:00,  1.31s/it]\n",
      "100%|██████████| 26/26 [00:44<00:00,  1.72s/it]\n",
      "100%|██████████| 26/26 [00:34<00:00,  1.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nREPLACE NUMBER IN HERE: \\n/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MRA 2024 Dataset (125 MRA) MULTICLASS from New Training\n",
    "### MRA 2024 Dataset (125 MRA) BINARY\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "pred_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/predictions'\n",
    "save_gt_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/ground-truth'\n",
    "save_roi_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/roi-metadata'\n",
    "\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "os.makedirs(save_gt_folder, exist_ok=True)\n",
    "os.makedirs(save_roi_folder, exist_ok=True)\n",
    "\n",
    "# seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/datasetnnUNet_trained_models/Dataset816_TopCoWSegMRACTA/nnUNetTrainerSkeletonRecallBinDiceNoMirroring__nnUNetPlans__3d_fullres'\n",
    "# seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/datasetnnUNet_trained_models/Dataset818_TopCoWSegMRAablation/nnUNetTrainerSkeletonRecallBinDiceNoMirroring__nnUNetPlans__3d_fullres'\n",
    "gt_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/cow_seg_labelsTr'\n",
    "roi_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/roi_loc_labelsTr'\n",
    "nfolds = 5\n",
    "\n",
    "for i in range(nfolds):\n",
    "    for file in tqdm(natsorted(os.listdir(os.path.join(seg_folder, f'fold_{i}/validation')))):\n",
    "        if file.startswith('topcow_mr_'):\n",
    "            init_name = os.path.join(seg_folder, f'fold_{i}/validation', file)\n",
    "            new_name = os.path.join(pred_folder, file)\n",
    "            # img = nib.load(init_name)\n",
    "            # arr = img.get_fdata()\n",
    "            # arr[arr == 13] = 15\n",
    "            # nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(gt_folder, file)\n",
    "            # img = nib.load(init_name)\n",
    "            # arr = 1*(img.get_fdata() > 0)\n",
    "            new_name = os.path.join(save_gt_folder, file)\n",
    "            # nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(roi_folder, file.split('.')[0]+'.txt')\n",
    "            new_name = os.path.join(save_roi_folder, file.split('.')[0]+'.txt')\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "'''\n",
    "REPLACE NUMBER IN HERE: \n",
    "/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.56s/it]\n",
      "100%|██████████| 25/25 [00:45<00:00,  1.80s/it]\n",
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n",
      "100%|██████████| 25/25 [00:37<00:00,  1.49s/it]\n",
      "100%|██████████| 25/25 [00:56<00:00,  2.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nREPLACE NUMBER IN HERE: \\n/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Ablation + post-processing assessment\n",
    "### MRA 2024 Dataset (125 MRA) MULTICLASS from New Training\n",
    "### MRA 2024 Dataset (125 MRA) BINARY\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "pred_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/predictions'\n",
    "save_gt_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/ground-truth'\n",
    "save_roi_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/roi-metadata'\n",
    "\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "os.makedirs(save_gt_folder, exist_ok=True)\n",
    "os.makedirs(save_roi_folder, exist_ok=True)\n",
    "\n",
    "# seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/datasetnnUNet_trained_models/Dataset816_TopCoWSegMRACTA/nnUNetTrainerSkeletonRecallBinDiceNoMirroring__nnUNetPlans__3d_fullres'\n",
    "# seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/evals/MRA_D818-def-skel_D810/with_pp_20' #MRA_D818-all_D810/with_pp_20'  # MRA_D818-default_D810, MRA_D818-def-skel-bin_D810, MRA_D818-def-skel_D810\n",
    "seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/evals/CTA_D806-all-best_D809-all_1000ep/with_pp_20' #'/home/hasna/miccai24_challenges/topcow_challenge/evals/806_cta_skr_bindice_nomir_5folds_val-best/without_pp' #'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/datasetnnUNet_trained_models/Dataset806_TopCoWSegCTAMRA/nnUNetTrainerSkeletonRecallBinDiceNoMirroring__nnUNetPlans__3d_fullres_ps' #'/home/hasna/miccai24_challenges/topcow_challenge/evals/CTA_D806-all_D809-all_1000ep/with_pp_20' #'/home/hasna/miccai24_challenges/topcow_challenge/evals/CTA_D815-all_D809-all_1000ep/with_pp_20'\n",
    "gt_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/cow_seg_labelsTr'\n",
    "roi_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/roi_loc_labelsTr'\n",
    "nfolds = 5  #5\n",
    "\n",
    "for i in range(nfolds):\n",
    "    for file in tqdm(natsorted(os.listdir(os.path.join(seg_folder, f'fold_{i}')))):  # FIXME: for 5 folds\n",
    "    # for file in tqdm(natsorted(os.list/dir(os.path.join(seg_folder, 'validation')))):  # FIXME: for -all\n",
    "        if file.startswith('topcow_ct_'):\n",
    "            init_name = os.path.join(seg_folder, f'fold_{i}', file)  # FIXME: for 5 folds\n",
    "            # init_name = os.path.join(seg_folder, f'validation', file)  # FIXME: for -all\n",
    "            new_name = os.path.join(pred_folder, file)\n",
    "            img = nib.load(init_name)\n",
    "            arr = img.get_fdata()\n",
    "            arr[arr == 13] = 15\n",
    "            # nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(gt_folder, file)\n",
    "            # img = nib.load(init_name)\n",
    "            # arr = 1*(img.get_fdata() > 0)\n",
    "            new_name = os.path.join(save_gt_folder, file)\n",
    "            # nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(roi_folder, file.split('.')[0]+'.txt')\n",
    "            new_name = os.path.join(save_roi_folder, file.split('.')[0]+'.txt')\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "'''\n",
    "REPLACE NUMBER IN HERE: \n",
    "/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:16<00:00,  1.48it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.55it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.49it/s]\n",
      "100%|██████████| 25/25 [00:14<00:00,  1.78it/s]\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nREPLACE NUMBER IN HERE: \\n/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FINAL VERSION for Paper\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "pred_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/predictions'\n",
    "save_gt_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/ground-truth'\n",
    "save_roi_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/roi-metadata'\n",
    "\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "os.makedirs(save_gt_folder, exist_ok=True)\n",
    "os.makedirs(save_roi_folder, exist_ok=True)\n",
    "\n",
    "seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/evals/final_CTA_bin809_mul806_skr-bindice_nomir_5folds_val-best/with_pp'   #with_pp\n",
    "gt_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/cow_seg_labelsTr'\n",
    "roi_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/roi_loc_labelsTr'\n",
    "nfolds = 5  # final_CTA_bin809_mul806_skr-bindice_nomir_5folds_val-best_with_pp\n",
    "\n",
    "for i in range(nfolds):\n",
    "    for file in tqdm(natsorted(os.listdir(os.path.join(seg_folder, f'fold_{i}')))):  # FIXME: for 5 folds\n",
    "        if file.startswith('topcow_ct_'):\n",
    "            init_name = os.path.join(seg_folder, f'fold_{i}', file)  # FIXME: for 5 folds\n",
    "            new_name = os.path.join(pred_folder, file)\n",
    "            img = nib.load(init_name)\n",
    "            arr = img.get_fdata()\n",
    "            arr[arr == 13] = 15\n",
    "            nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(gt_folder, file)\n",
    "            # img = nib.load(init_name)\n",
    "            # arr = 1*(img.get_fdata() > 0)\n",
    "            new_name = os.path.join(save_gt_folder, file)\n",
    "            # nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(roi_folder, file.split('.')[0]+'.txt')\n",
    "            new_name = os.path.join(save_roi_folder, file.split('.')[0]+'.txt')\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "'''\n",
    "REPLACE NUMBER IN HERE: \n",
    "/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 3813.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nREPLACE NUMBER IN HERE: \\n/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MRA 2024 Dataset (2 folds)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "pred_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/predictions'\n",
    "save_gt_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/ground-truth'\n",
    "save_roi_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/roi-metadata'\n",
    "\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "os.makedirs(save_gt_folder, exist_ok=True)\n",
    "os.makedirs(save_roi_folder, exist_ok=True)\n",
    "\n",
    "# mra_skr_bindice_withmir_fold-1_with_pp\n",
    "# mra_skr_bindice_withmir_fold-1_without_pp\n",
    "seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge_final/evals/mra_skr_bindice_withmir_2folds/without_pp'\n",
    "\n",
    "# mra_skr_bindice_nomir_fold-1_without_pp\n",
    "# mra_skr_bindice_nomir_fold-1_with_pp\n",
    "# seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge_final/evals/mra_skr_bindice_nomir_5folds/without_pp'\n",
    "# gt_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/cow_seg_labelsTr'\n",
    "# roi_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/roi_loc_labelsTr'\n",
    "# nfolds = 1\n",
    "\n",
    "for i in [1]: #range(nfolds):\n",
    "    for file in tqdm(natsorted(os.listdir(os.path.join(seg_folder, f'fold_{i}')))):\n",
    "        if file.endswith('.nii.gz'):\n",
    "            init_name = os.path.join(seg_folder, f'fold_{i}', file)\n",
    "            new_name = os.path.join(pred_folder, file)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(gt_folder, file)\n",
    "            new_name = os.path.join(save_gt_folder, file)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(roi_folder, file.split('.')[0]+'.txt')\n",
    "            new_name = os.path.join(save_roi_folder, file.split('.')[0]+'.txt')\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "\n",
    "'''\n",
    "REPLACE NUMBER IN HERE: \n",
    "/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "with open('/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/output/metrics_mra_skr_bindice_nomir_5folds_with_pp.json', 'r') as file:\n",
    "    metrics_with_pp = json.load(file)\n",
    "with open('/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/output/metrics_mra_skr_bindice_nomir_5folds_without_pp.json', 'r') as file:\n",
    "    metrics_without_pp = json.load(file)\n",
    "with open('/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/dataset/preprocessed/Dataset808_TopCoWSegMRA/splits_final.json', 'r') as file:\n",
    "    splits = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>index</th>\n",
       "      <th>val_with_pp</th>\n",
       "      <th>val_without_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>7</td>\n",
       "      <td>0.801426</td>\n",
       "      <td>0.836272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>41</td>\n",
       "      <td>0.698666</td>\n",
       "      <td>0.763709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>93</td>\n",
       "      <td>0.899800</td>\n",
       "      <td>0.915267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>100</td>\n",
       "      <td>0.892367</td>\n",
       "      <td>0.909599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>110</td>\n",
       "      <td>0.880562</td>\n",
       "      <td>0.942338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>119</td>\n",
       "      <td>0.847899</td>\n",
       "      <td>0.871679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            metric index  val_with_pp  val_without_pp\n",
       "0  Dice_ClsAvgDice     7     0.801426        0.836272\n",
       "1  Dice_ClsAvgDice    41     0.698666        0.763709\n",
       "2  Dice_ClsAvgDice    93     0.899800        0.915267\n",
       "3  Dice_ClsAvgDice   100     0.892367        0.909599\n",
       "4  Dice_ClsAvgDice   110     0.880562        0.942338\n",
       "5  Dice_ClsAvgDice   119     0.847899        0.871679"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "metrics_with_pp['case'].keys()\n",
    "metrics_with_pp['case']['Dice_ClsAvgDice']\n",
    "metrics_with_pp['case']['HD95_ClsAvgHD95']\n",
    "metrics_with_pp['case']['clDice']\n",
    "\n",
    "\n",
    "mets = ['Dice_ClsAvgDice', 'clDice']  #'HD95_ClsAvgHD95\n",
    "df = pd.DataFrame(columns=['metric', 'index', 'val_with_pp', 'val_without_pp'])\n",
    "for met in mets:\n",
    "    for idx, val in metrics_with_pp['case'][met].items():\n",
    "        if val < metrics_without_pp['case'][met][idx] - 0.015:\n",
    "            new_row = pd.DataFrame({\n",
    "                'metric': [met],\n",
    "                'index': [int(idx)+1],\n",
    "                'val_with_pp': [val],\n",
    "                'val_without_pp': [metrics_without_pp['case'][met][idx]]\n",
    "            })\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "df[df['metric'] == 'Dice_ClsAvgDice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>index</th>\n",
       "      <th>val_with_pp</th>\n",
       "      <th>val_without_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>7</td>\n",
       "      <td>0.801426</td>\n",
       "      <td>0.836272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>8</td>\n",
       "      <td>0.922731</td>\n",
       "      <td>0.924010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>9</td>\n",
       "      <td>0.794300</td>\n",
       "      <td>0.795986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>13</td>\n",
       "      <td>0.807366</td>\n",
       "      <td>0.809266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>15</td>\n",
       "      <td>0.689932</td>\n",
       "      <td>0.694921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>17</td>\n",
       "      <td>0.848003</td>\n",
       "      <td>0.848094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>20</td>\n",
       "      <td>0.837560</td>\n",
       "      <td>0.839046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>25</td>\n",
       "      <td>0.892822</td>\n",
       "      <td>0.898452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>32</td>\n",
       "      <td>0.873819</td>\n",
       "      <td>0.878243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>34</td>\n",
       "      <td>0.797894</td>\n",
       "      <td>0.800841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>35</td>\n",
       "      <td>0.778488</td>\n",
       "      <td>0.782804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>41</td>\n",
       "      <td>0.698666</td>\n",
       "      <td>0.763709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>42</td>\n",
       "      <td>0.748790</td>\n",
       "      <td>0.752135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>43</td>\n",
       "      <td>0.775943</td>\n",
       "      <td>0.775995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>44</td>\n",
       "      <td>0.830034</td>\n",
       "      <td>0.840135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>45</td>\n",
       "      <td>0.835365</td>\n",
       "      <td>0.836516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>48</td>\n",
       "      <td>0.924776</td>\n",
       "      <td>0.934830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>50</td>\n",
       "      <td>0.920381</td>\n",
       "      <td>0.924737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>52</td>\n",
       "      <td>0.915156</td>\n",
       "      <td>0.915598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>53</td>\n",
       "      <td>0.943216</td>\n",
       "      <td>0.944825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>56</td>\n",
       "      <td>0.897402</td>\n",
       "      <td>0.898895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>59</td>\n",
       "      <td>0.789455</td>\n",
       "      <td>0.790051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>61</td>\n",
       "      <td>0.866502</td>\n",
       "      <td>0.868604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>63</td>\n",
       "      <td>0.868915</td>\n",
       "      <td>0.868932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>66</td>\n",
       "      <td>0.880155</td>\n",
       "      <td>0.885613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>73</td>\n",
       "      <td>0.843627</td>\n",
       "      <td>0.844741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>74</td>\n",
       "      <td>0.887693</td>\n",
       "      <td>0.892002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>86</td>\n",
       "      <td>0.925590</td>\n",
       "      <td>0.930894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>89</td>\n",
       "      <td>0.851195</td>\n",
       "      <td>0.851309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>90</td>\n",
       "      <td>0.910687</td>\n",
       "      <td>0.912917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>91</td>\n",
       "      <td>0.832424</td>\n",
       "      <td>0.835828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>92</td>\n",
       "      <td>0.942366</td>\n",
       "      <td>0.944085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>93</td>\n",
       "      <td>0.899800</td>\n",
       "      <td>0.915267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>94</td>\n",
       "      <td>0.936983</td>\n",
       "      <td>0.943809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>97</td>\n",
       "      <td>0.903155</td>\n",
       "      <td>0.904366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>100</td>\n",
       "      <td>0.892367</td>\n",
       "      <td>0.909599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>102</td>\n",
       "      <td>0.951192</td>\n",
       "      <td>0.955202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>104</td>\n",
       "      <td>0.856059</td>\n",
       "      <td>0.856195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>108</td>\n",
       "      <td>0.813287</td>\n",
       "      <td>0.818455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>110</td>\n",
       "      <td>0.880562</td>\n",
       "      <td>0.942338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>112</td>\n",
       "      <td>0.892892</td>\n",
       "      <td>0.896277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>114</td>\n",
       "      <td>0.859093</td>\n",
       "      <td>0.859188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>117</td>\n",
       "      <td>0.937598</td>\n",
       "      <td>0.942666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>119</td>\n",
       "      <td>0.847899</td>\n",
       "      <td>0.871679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Dice_ClsAvgDice</td>\n",
       "      <td>120</td>\n",
       "      <td>0.957178</td>\n",
       "      <td>0.961091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             metric index  val_with_pp  val_without_pp\n",
       "0   Dice_ClsAvgDice     7     0.801426        0.836272\n",
       "1   Dice_ClsAvgDice     8     0.922731        0.924010\n",
       "2   Dice_ClsAvgDice     9     0.794300        0.795986\n",
       "3   Dice_ClsAvgDice    13     0.807366        0.809266\n",
       "4   Dice_ClsAvgDice    15     0.689932        0.694921\n",
       "5   Dice_ClsAvgDice    17     0.848003        0.848094\n",
       "6   Dice_ClsAvgDice    20     0.837560        0.839046\n",
       "7   Dice_ClsAvgDice    25     0.892822        0.898452\n",
       "8   Dice_ClsAvgDice    32     0.873819        0.878243\n",
       "9   Dice_ClsAvgDice    34     0.797894        0.800841\n",
       "10  Dice_ClsAvgDice    35     0.778488        0.782804\n",
       "11  Dice_ClsAvgDice    41     0.698666        0.763709\n",
       "12  Dice_ClsAvgDice    42     0.748790        0.752135\n",
       "13  Dice_ClsAvgDice    43     0.775943        0.775995\n",
       "14  Dice_ClsAvgDice    44     0.830034        0.840135\n",
       "15  Dice_ClsAvgDice    45     0.835365        0.836516\n",
       "16  Dice_ClsAvgDice    48     0.924776        0.934830\n",
       "17  Dice_ClsAvgDice    50     0.920381        0.924737\n",
       "18  Dice_ClsAvgDice    52     0.915156        0.915598\n",
       "19  Dice_ClsAvgDice    53     0.943216        0.944825\n",
       "20  Dice_ClsAvgDice    56     0.897402        0.898895\n",
       "21  Dice_ClsAvgDice    59     0.789455        0.790051\n",
       "22  Dice_ClsAvgDice    61     0.866502        0.868604\n",
       "23  Dice_ClsAvgDice    63     0.868915        0.868932\n",
       "24  Dice_ClsAvgDice    66     0.880155        0.885613\n",
       "25  Dice_ClsAvgDice    73     0.843627        0.844741\n",
       "26  Dice_ClsAvgDice    74     0.887693        0.892002\n",
       "27  Dice_ClsAvgDice    86     0.925590        0.930894\n",
       "28  Dice_ClsAvgDice    89     0.851195        0.851309\n",
       "29  Dice_ClsAvgDice    90     0.910687        0.912917\n",
       "30  Dice_ClsAvgDice    91     0.832424        0.835828\n",
       "31  Dice_ClsAvgDice    92     0.942366        0.944085\n",
       "32  Dice_ClsAvgDice    93     0.899800        0.915267\n",
       "33  Dice_ClsAvgDice    94     0.936983        0.943809\n",
       "34  Dice_ClsAvgDice    97     0.903155        0.904366\n",
       "35  Dice_ClsAvgDice   100     0.892367        0.909599\n",
       "36  Dice_ClsAvgDice   102     0.951192        0.955202\n",
       "37  Dice_ClsAvgDice   104     0.856059        0.856195\n",
       "38  Dice_ClsAvgDice   108     0.813287        0.818455\n",
       "39  Dice_ClsAvgDice   110     0.880562        0.942338\n",
       "40  Dice_ClsAvgDice   112     0.892892        0.896277\n",
       "41  Dice_ClsAvgDice   114     0.859093        0.859188\n",
       "42  Dice_ClsAvgDice   117     0.937598        0.942666\n",
       "43  Dice_ClsAvgDice   119     0.847899        0.871679\n",
       "44  Dice_ClsAvgDice   120     0.957178        0.961091"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "metrics_with_pp['case'].keys()\n",
    "metrics_with_pp['case']['Dice_ClsAvgDice']\n",
    "metrics_with_pp['case']['HD95_ClsAvgHD95']\n",
    "metrics_with_pp['case']['clDice']\n",
    "\n",
    "\n",
    "mets = ['Dice_ClsAvgDice', 'HD95_ClsAvgHD95', 'clDice']\n",
    "df = pd.DataFrame(columns=['metric', 'index', 'val_with_pp', 'val_without_pp'])\n",
    "for met in mets:\n",
    "    for idx, val in metrics_with_pp['case'][met].items():\n",
    "        if val < metrics_without_pp['case'][met][idx]:\n",
    "            new_row = pd.DataFrame({\n",
    "                'metric': [met],\n",
    "                'index': [int(idx)+1],\n",
    "                'val_with_pp': [val],\n",
    "                'val_without_pp': [metrics_without_pp['case'][met][idx]]\n",
    "            })\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "df[df['metric'] == 'Dice_ClsAvgDice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = (df[df['metric'] == 'Dice_ClsAvgDice']['index'])\n",
    "# r = [[int(splits[j]['val'][i].split('_')[-1]) for i in range(len(splits[0]['val']))] for j in range(5)]\n",
    "\n",
    "# target = [int(x) for x in list(l)]\n",
    "# result = {}\n",
    "\n",
    "# for num in target:\n",
    "#     # Find which sublist contains the number\n",
    "#     indices = [i for i, sublist in enumerate(r) if num in sublist]\n",
    "#     result[num] = indices\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liu's Topology refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "git clone https://github.com/smilell/Universal-Topology-Refinement.git\n",
    "\n",
    ">>> For testing:\n",
    "python /home/hasna/miccai24_challenges/Universal-Topology-Refinement/main.py --phase test_post --trained_model_post ./model_1/poly_1/ --out ./output_1/poly_1/ --TBout./output_1/poly_1/ --test_softmax ./data/cremi_2d/test/softmax/\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 824.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "main_dir = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/preprocessed/Dataset811_TopCoWSegBinMRACTA/nnUNetPlans_3d_fullres'\n",
    "for file in tqdm(natsorted(os.listdir(main_dir))):\n",
    "    if file.endswith('.npy'):\n",
    "        # os.remove(os.path.join(main_dir, file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet_epvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
