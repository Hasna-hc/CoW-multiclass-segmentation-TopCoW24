{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "conda update -n base conda &&\n",
    "conda install -n base conda-libmamba-solver &&\n",
    "conda config --set solver libmamba &&\n",
    "source ~/anaconda3/bin/activate\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "conda create -n nnunet_topcow2024 python==3.9.13 anaconda -y\n",
    "conda activate nnunet_topcow2024\n",
    "conda update -n nnunet_topcow2024 conda -y\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "conda create -n nnunet_topcow24 python==3.9.13 anaconda -y\n",
    "conda activate nnunet_topcow24\n",
    "conda update -n nnunet_topcow24 conda -y\n",
    "\n",
    "### MODIFIED THIS FILE : /home/hasna/miniconda3/envs/nnunet_topcow24/lib/python3.9/site-packages/acvl_utils/cropping_and_padding/bounding_boxes.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# pip install -r requirements.txt\n",
    "pip install -r /home/hasna/nnUNet_dir/requirements.txt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "pip install threadpoolctl==3.1.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "export PYTHONPATH=\"${PYTHONPATH}:/home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Preparing nnUNet*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Installation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Following instructions from:\n",
    "https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/installation_instructions.md\n",
    "pip install -e . \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Dataset format*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob \n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from collections import OrderedDict\n",
    "from scipy.ndimage import find_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1 - CoW Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:52<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Binary MRA segmentation using MRA only '''\n",
    "\n",
    "dataset_name = 'Dataset802_TopCoWSegBinMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_mr_'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data = 1*(data>0)\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:29<00:00,  2.78it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Binary CTA segmentation using CTA only '''\n",
    "\n",
    "dataset_name = 'Dataset809_TopCoWSegBinCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_ct_'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data = 1*(data>0)\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [05:33<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "''' CTA and MRA for multiclass seg in the final version for CTA '''\n",
    "\n",
    "dataset_name = 'Dataset806_TopCoWSegCTAMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.endswith('.nii.gz'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data[data==15] = 13\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:07<00:00,  3.69it/s] \n"
     ]
    }
   ],
   "source": [
    "''' Multiclass MRA only '''\n",
    "\n",
    "dataset_name = 'Dataset808_TopCoWSegMRA' #'Dataset703_TopCoWDetCTAextendedMask' #'Dataset701_TopCoWDetCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Renaming according to nnUNet: \n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_mr_'):                \n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # # shutil.copy(init_name, new_name)\n",
    "\n",
    "        init_name = os.path.join(data_folder, 'cow_seg_labelsTr', sub)\n",
    "        new_name = os.path.join(data_path, subfold[1], sub)\n",
    "        img = nib.load(init_name)\n",
    "        data = img.get_fdata()\n",
    "        data[data==15] = 13\n",
    "        data = data.astype(np.uint8)\n",
    "        new_img = nib.Nifti1Image(data, img.affine, img.header)\n",
    "        # # nib.save(new_img, new_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2 - CoW Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_bounding_box_3d(mask):\n",
    "    \"\"\"\n",
    "    Given a 3D binary mask, returns the bounding box size and location in the format:\n",
    "    (size_x, size_y, size_z), (min_x, min_y, min_z)\n",
    "    \"\"\"\n",
    "    slices = find_objects(mask)\n",
    "    if slices and slices[0] is not None:\n",
    "        min_x, min_y, min_z = slices[0][0].start, slices[0][1].start, slices[0][2].start\n",
    "        max_x, max_y, max_z = slices[0][0].stop, slices[0][1].stop, slices[0][2].stop\n",
    "        return min_x, max_x, min_y, max_y, min_z, max_z\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Extend in the low part:\n",
    "def extend_mask(seg_mask, roi_mask):\n",
    "    seg_min_x, seg_max_x, seg_min_y, seg_max_y, seg_min_z, seg_max_z = get_bounding_box_3d(seg_mask)\n",
    "    roi_min_x, roi_max_x, roi_min_y, roi_max_y, roi_min_z, roi_max_z = get_bounding_box_3d(roi_mask)\n",
    "\n",
    "    if roi_min_x < seg_min_x:\n",
    "        seg_mask[roi_min_x:seg_min_x, :, :] = np.repeat(seg_mask[seg_min_x:seg_min_x+1, :, :], seg_min_x - roi_min_x, axis=0)\n",
    "    if roi_min_y < seg_min_y:\n",
    "        seg_mask[:, roi_min_y:seg_min_y, :] = np.repeat(seg_mask[:, seg_min_y:seg_min_y+1, :], seg_min_y - roi_min_y, axis=1)\n",
    "    if roi_min_z < seg_min_z:\n",
    "        seg_mask[:, :, roi_min_z:seg_min_z] = np.repeat(seg_mask[:, :, seg_min_z:seg_min_z+1], seg_min_z - roi_min_z, axis=2)\n",
    "\n",
    "    # Extend in the high part:\n",
    "    if roi_max_x > seg_max_x:\n",
    "        seg_mask[seg_max_x:roi_max_x, :, :] = np.repeat(seg_mask[seg_max_x-1:seg_max_x, :, :], roi_max_x - seg_max_x, axis=0)\n",
    "    if roi_max_y > seg_max_y:\n",
    "        seg_mask[:, seg_max_y:roi_max_y, :] = np.repeat(seg_mask[:, seg_max_y-1:seg_max_y, :], roi_max_y - seg_max_y, axis=1)\n",
    "    if roi_max_z > seg_max_z:\n",
    "        seg_mask[:, :, seg_max_z:roi_max_z] = np.repeat(seg_mask[:, :, seg_max_z-1:seg_max_z], roi_max_z - seg_max_z, axis=2)\n",
    "\n",
    "    return seg_mask\n",
    "\n",
    "\n",
    "# print(seg_min_x, seg_max_x, seg_min_y, seg_max_y, seg_min_z, seg_max_z)\n",
    "# print(roi_min_x, roi_max_x, roi_min_y, roi_max_y, roi_min_z, roi_max_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [07:24<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "''' MRA Box task with MRA only '''\n",
    "\n",
    "dataset_name = 'Dataset704_TopCoWDetMRAextendedMask'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "data_path = f'/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/{dataset_name}'\n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "\n",
    "subfold = ['imagesTr', 'labelsTr']\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.startswith('topcow_mr_'):\n",
    "        init_name = os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        new_name = os.path.join(data_path, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\")\n",
    "        # shutil.copy(init_name, new_name)\n",
    "\n",
    "        bbox_image = nib.load(os.path.join(data_folder, 'roi_masks', sub)).get_fdata().astype(np.uint8)\n",
    "        nifti_image = nib.load(os.path.join(data_folder, 'cow_seg_labelsTr', sub))\n",
    "        binary_image = (nifti_image.get_fdata() > 0).astype(int)\n",
    "        cropped_mask = binary_image*bbox_image\n",
    "\n",
    "        extended_mask = extend_mask(cropped_mask, bbox_image)\n",
    "        # nib.save(nib.Nifti1Image(extended_mask.astype('int32'), affine=nifti_image.affine), os.path.join(data_path, subfold[1], sub))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CTA Box task with CTA + MRA '''\n",
    "\n",
    "dataset_name = 'Dataset705_TopCoWDetCTAextendedMaskCTAMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok = True)\n",
    "os.makedirs(train_label_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "### ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "cta_imgs = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/Dataset703_TopCoWDetCTACropExtendedMulSegMask/imagesTr'\n",
    "cta_labs = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/Dataset703_TopCoWDetCTACropExtendedMulSegMask/labelsTr'\n",
    "mra_imgs = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/Dataset704_TopCoWDetMRAextendedMask/imagesTr'\n",
    "mra_labs = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw/Dataset704_TopCoWDetMRAextendedMask/labelsTr'\n",
    "\n",
    "for file in tqdm(natsorted(os.listdir(cta_labs))):\n",
    "    init_name = os.path.join(cta_imgs, file.split('.')[0]+'_0000.nii.gz')\n",
    "    new_name = os.path.join(train_image_dir, file.split('.')[0]+'_0000.nii.gz')\n",
    "    # # shutil.copy(init_name, new_name)\n",
    "\n",
    "    init_name = os.path.join(cta_labs, file)\n",
    "    new_name = os.path.join(train_label_dir, file)\n",
    "    # # shutil.copy(init_name, new_name)\n",
    "\n",
    "\n",
    "for file in tqdm(natsorted(os.listdir(mra_labs))):\n",
    "    init_name = os.path.join(mra_imgs, file.split('.')[0]+'_0000.nii.gz')\n",
    "    new_name = os.path.join(train_image_dir, file.split('.')[0]+'_0000.nii.gz')\n",
    "    # # shutil.copy(init_name, new_name)\n",
    "\n",
    "    init_name = os.path.join(mra_labs, file)\n",
    "    new_name = os.path.join(train_label_dir, file)\n",
    "    # # shutil.copy(init_name, new_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Preparing dataset.json file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "''' Task 2: CoW Detection '''\n",
    "\n",
    "dataset_name = 'Dataset705_TopCoWDetCTAextendedMaskCTAMRA' #'Dataset704_TopCoWDetMRAextendedMask'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Multiclass CoW roi Detection task using CTA but trained on CTA+MRA and bin label mask cropped from the multiclass GT and extended to have ROI bbox, trained for 5 folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"ctamra\",\n",
    "        # \"1\": \"binmask\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"cow\" : 1,\n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Task 1: CoW Segmentation '''\n",
    "### Binary CTA for CTA\n",
    "\n",
    "dataset_name = 'Dataset809_TopCoWSegBinCTA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Binary CoW segmentation task for CTA using CTA only, trained for all folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"cta\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"cow\" : 1        \n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "''' Task 1: CoW Segmentation '''\n",
    "### Multiclass CTAMRA for CTA\n",
    "\n",
    "dataset_name = 'Dataset806_TopCoWSegCTAMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Multiclass CoW segmentation task for CTA using CTA+MRA, trained for all folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"ctamra\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"BA\" : 1,\n",
    "        \"R-PCA\" : 2,\n",
    "        \"L-PCA\" : 3,\n",
    "        \"R-ICA\" : 4,\n",
    "        \"R-MCA\" : 5,\n",
    "        \"L-ICA\" : 6,\n",
    "        \"L-MCA\" : 7,\n",
    "        \"R-Pcom\" : 8,\n",
    "        \"L-Pcom\" : 9,\n",
    "        \"Acom\" : 10,\n",
    "        \"R-ACA\" : 11,\n",
    "        \"L-ACA\" : 12,\n",
    "        \"3rd-A2\" : 13\n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Task 1: CoW Segmentation '''\n",
    "### Binary MRA for MRA\n",
    "\n",
    "dataset_name = 'Dataset802_TopCoWSegBinMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Binary CoW segmentation task for MRA using MRA only, trained for all folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"mra\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"cow\" : 1        \n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "''' Task 1: CoW Segmentation '''\n",
    "### Multiclass MRA for MRA\n",
    "\n",
    "dataset_name = 'Dataset808_TopCoWSegMRA'\n",
    "nnunet_basedir = \"/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir\"\n",
    "dataset_folder_name = os.path.join(nnunet_basedir, 'dataset/nnUNet_raw/', dataset_name)\n",
    "train_image_dir = os.path.join(dataset_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(dataset_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(dataset_folder_name,'imagesTs')\n",
    "\n",
    "dataset_json_path = os.path.join(dataset_folder_name, 'dataset.json')\n",
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(dataset_json_path):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['dataset_name'] = dataset_name\n",
    "    json_dict['description'] = \"Multiclass CoW segmentation task for MRA, trained on 5 folds for the TopCoW2024 Challenge\" #\"Binary CoW roi Detection task using CTA and Binary segmentation mask from the multiclass GT, trained for 5 folds for the TopCoW2024 Challenge\"\n",
    "    json_dict['tensor_image_size'] = \"3D\"\n",
    "    json_dict['file_ending'] = \".nii.gz\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['channel_names'] = {\n",
    "        \"0\": \"mra\",\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"background\": 0,\n",
    "        \"BA\" : 1,\n",
    "        \"R-PCA\" : 2,\n",
    "        \"L-PCA\" : 3,\n",
    "        \"R-ICA\" : 4,\n",
    "        \"R-MCA\" : 5,\n",
    "        \"L-ICA\" : 6,\n",
    "        \"L-MCA\" : 7,\n",
    "        \"R-Pcom\" : 8,\n",
    "        \"L-Pcom\" : 9,\n",
    "        \"Acom\" : 10,\n",
    "        \"R-ACA\" : 11,\n",
    "        \"L-ACA\" : 12,\n",
    "        \"3rd-A2\" : 13\n",
    "    }\n",
    "\n",
    "    train_ids = sorted(os.listdir(train_label_dir))\n",
    "    test_ids = sorted(os.listdir(test_dir))\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTesting'] = len(test_ids)\n",
    "\n",
    "    # no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    # removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % i for i in test_ids]\n",
    "\n",
    "    with open(dataset_json_path, 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(dataset_json_path):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [03:22<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Information about Spacings and Sizes of all modalities '''\n",
    "\n",
    "dataset_name = 'Dataset701_TopCoWDetCTA' \n",
    "# Renaming according to nnUNet: \n",
    "data_folder = '/home/hasna/datasets/TopCoW2024_Data_Release'\n",
    "subfold = ['imagesTr', 'cow_seg_labelsTr']\n",
    "\n",
    "mri_spacing, seg_spacing = [], []\n",
    "mri_size, seg_size = [], []\n",
    "labels = []\n",
    "fnames = []\n",
    "\n",
    "# imageTr:\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'cow_seg_labelsTr')))):\n",
    "    if sub.endswith('.nii.gz'):        \n",
    "        mri = sitk.ReadImage(os.path.join(data_folder, subfold[0], f\"{sub.split('.')[0]}_0000.nii.gz\"))\n",
    "        mri_spacing.append(mri.GetSpacing())\n",
    "        mri_size.append(mri.GetSize())\n",
    "        \n",
    "        seg = sitk.ReadImage(os.path.join(data_folder, subfold[1], sub))\n",
    "        seg_spacing.append(seg.GetSpacing())\n",
    "        seg_size.append(seg.GetSize())\n",
    "\n",
    "        fnames.append(sub.split('.')[0])\n",
    "        labels.append(sitk.GetArrayFromImage(seg).max())\n",
    "\n",
    "df = pd.DataFrame({'filename':fnames, 'mri_spacing':mri_spacing, 'seg_spacing':seg_spacing, 'mri_size':mri_size, 'seg_size':seg_size, 'max_label':labels})\n",
    "# df.to_csv('/home/hasna/miccai24_challenges/topcow_challenge/topcow24_dataset_spacing_size.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:18<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "''' Information about Spacings and Sizes of all modalities '''\n",
    "\n",
    "data_folder = '/home/hasna/datasets/crown_20_mr_01062023'\n",
    "\n",
    "mri_spacing, seg_spacing = [], []\n",
    "mri_size, seg_size = [], []\n",
    "labels = []\n",
    "fnames = []\n",
    "\n",
    "# imageTr:\n",
    "for sub in tqdm(natsorted(os.listdir(os.path.join(data_folder, 'mul_labelsTr')))):\n",
    "    if sub.startswith('crown_mr_whole'):        \n",
    "        mri = sitk.ReadImage(os.path.join(data_folder, 'imagesTr', f\"{sub.split('.')[0]}_0000.nii.gz\"))\n",
    "        mri_spacing.append(mri.GetSpacing())\n",
    "        mri_size.append(mri.GetSize())\n",
    "        \n",
    "        seg = sitk.ReadImage(os.path.join(data_folder, 'mul_labelsTr', sub))\n",
    "        seg_spacing.append(seg.GetSpacing())\n",
    "        seg_size.append(seg.GetSize())\n",
    "\n",
    "        fnames.append(sub.split('.')[0])\n",
    "        labels.append(sitk.GetArrayFromImage(seg).max())\n",
    "\n",
    "df = pd.DataFrame({'filename':fnames, 'mri_spacing':mri_spacing, 'seg_spacing':seg_spacing, 'mri_size':mri_size, 'seg_size':seg_size, 'max_label':labels})\n",
    "# df.to_csv('/home/hasna/miccai24_challenges/topcow_challenge/crown23_dataset_spacing_size.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Training nnUNet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nexport nnUNet_raw='/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/dataset/nnUNet_raw'\\nexport nnUNet_preprocessed='/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/dataset/preprocessed'\\nexport nnUNet_results='/home/hasna/miccai24_challenges/topcow_challenge_final/nnunet_dir/datasetnnUNet_trained_models'\\n\\n\\n>>> For task 1:\\nnnUNetv2_extract_fingerprint -d 802 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 802 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 802 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\\nnnUNetv2_extract_fingerprint -d 806 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 806 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 806 -c 3d_fullres_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\\nnnUNetv2_extract_fingerprint -d 807 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 807 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 807 -c 3d_fullres_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\\nnnUNetv2_extract_fingerprint -d 808 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 808 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 808 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\\n\\n>>> For task 2:\\nnnUNetv2_extract_fingerprint -d 704 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 704 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 704 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\\nnnUNetv2_extract_fingerprint -d 705 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\\nnnUNetv2_plan_experiment -d 705 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\\nnnUNetv2_preprocess -d 705 -c 3d_fullres_spacing_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "export nnUNet_raw='/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw'\n",
    "export nnUNet_preprocessed='/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/preprocessed'\n",
    "export nnUNet_results='/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/datasetnnUNet_trained_models'\n",
    "\n",
    "\n",
    ">>> For task 1:\n",
    "nnUNetv2_extract_fingerprint -d 802 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 802 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 802 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 806 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 806 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 806 -c 3d_fullres_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 808 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 808 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 808 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 809 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 809 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 809 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">>> For task 2:\n",
    "nnUNetv2_extract_fingerprint -d 704 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 704 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 704 -c 3d_fullres -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "\n",
    "nnUNetv2_extract_fingerprint -d 705 --verify_dataset_integrity   # --> to get the 'dataset_fingerprint.json'\n",
    "nnUNetv2_plan_experiment -d 705 --verify_dataset_integrity   # --> to get the 'dataset.json' and 'nnUNetPlans.json'\n",
    "nnUNetv2_preprocess -d 705 -c 3d_fullres_spacing_ps -np 8 --verify_dataset_integrity   # --> to get the 'gt_segmentations' and 'nnUNetPlans_3d_fullres' ...\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "export nnUNet_raw='/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/nnUNet_raw'\n",
    "export nnUNet_preprocessed='/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/preprocessed'\n",
    "export nnUNet_results='/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/datasetnnUNet_trained_models'\n",
    "'''\n",
    "\n",
    "''' For task 2: -------------------------------------------------------------------------------------------\n",
    ">>> Finetuning 704:  MAKE SURE THE SPLIT HAS NO DATA LEAKAGE\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 704 3d_fullres 0 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset102_Binseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 704 3d_fullres 1 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset102_Binseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_1/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 704 3d_fullres 2 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset102_Binseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_2/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 704 3d_fullres 3 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset102_Binseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_3/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 704 3d_fullres 4 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset102_Binseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_4/checkpoint_best.pth\n",
    "\n",
    ">>> Training 704:  3folds\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 704 3d_fullres 0 -tr nnUNetTrainerSkeletonRecall\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 704 3d_fullres 1 -tr nnUNetTrainerSkeletonRecall\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 704 3d_fullres 2 -tr nnUNetTrainerSkeletonRecall\n",
    "\n",
    "\n",
    ">>> Finetuning 705:  MAKE SURE THE SPLIT HAS NO DATA LEAKAGE\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 705 3d_fullres_spacing_ps 0 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir/dataset/preprocessed/Dataset702_TopCoWDetCTACroppedMulSegMask/pretrained_checkpoints/checkpoint_best_fold0.pth\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 705 3d_fullres_spacing_ps 1 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir/dataset/preprocessed/Dataset702_TopCoWDetCTACroppedMulSegMask/pretrained_checkpoints/checkpoint_best_fold1.pth\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 705 3d_fullres_spacing_ps 2 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir/dataset/preprocessed/Dataset702_TopCoWDetCTACroppedMulSegMask/pretrained_checkpoints/checkpoint_best_fold2.pth\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 705 3d_fullres_spacing_ps 3 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir/dataset/preprocessed/Dataset702_TopCoWDetCTACroppedMulSegMask/pretrained_checkpoints/checkpoint_best_fold3.pth\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 705 3d_fullres_spacing_ps 4 -tr nnUNetTrainerSkeletonRecall -pretrained_weights /home/hasna/miccai24_challenges/epvs_challenge/nnunet_dir/dataset/preprocessed/Dataset702_TopCoWDetCTACroppedMulSegMask/pretrained_checkpoints/checkpoint_best_fold4.pth\n",
    "'''\n",
    "\n",
    "''' For task 1: -------------------------------------------------------------------------------------------\n",
    ">>> Training for MRA:\n",
    ">> [Binary - MRA only]:\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 802 3d_fullres all -tr nnUNetTrainerSkeletonRecall\n",
    "\n",
    ">> [Multiclass - MRA only]:\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 808 3d_fullres 0 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset101_Mulseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_0/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 808 3d_fullres 1 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset101_Mulseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_1/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 808 3d_fullres 2 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset101_Mulseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_2/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 808 3d_fullres 3 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset101_Mulseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_3/checkpoint_best.pth\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 808 3d_fullres 4 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring -pretrained_weights /home/hasna/miccai24_challenges/topcow_challenge/Dataset101_Mulseg/nnUNetTrainer__nnUNetPlans__3d_fullres/fold_4/checkpoint_best.pth\n",
    "\n",
    "\n",
    ">>> Training for CTA:\n",
    ">> [Binary - CTA only]:\n",
    "CUDA_VISIBLE_DEVICES=2 nnUNetv2_train 809 3d_fullres all -tr nnUNetTrainerSkeletonRecall --val_best\n",
    "\n",
    ">> [Multiclass - CTA+MRA]\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 806 3d_fullres_ps 0 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 806 3d_fullres_ps 1 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring\n",
    "CUDA_VISIBLE_DEVICES=3 nnUNetv2_train 806 3d_fullres_ps 2 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring\n",
    "CUDA_VISIBLE_DEVICES=0 nnUNetv2_train 806 3d_fullres_ps 3 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring\n",
    "CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 806 3d_fullres_ps 4 -tr nnUNetTrainerSkeletonRecallBinDiceNoMirroring\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cd /home/hasna/miccai24_challenges/TopCoW_Algo_Submission/task-2-box   #/task-1-seg\n",
    "bash test_run.sh\n",
    "bash save.sh\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:34<00:00,  1.37s/it]\n",
      "100%|██████████| 25/25 [00:33<00:00,  1.36s/it]\n",
      "100%|██████████| 25/25 [00:30<00:00,  1.22s/it]\n",
      "100%|██████████| 25/25 [00:29<00:00,  1.19s/it]\n",
      "100%|██████████| 25/25 [00:30<00:00,  1.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nREPLACE NUMBERS IN HERE: \\n/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FINAL VERSION\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "pred_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/predictions'\n",
    "save_gt_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/ground-truth'\n",
    "save_roi_folder = '/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/roi-metadata'\n",
    "\n",
    "os.makedirs(pred_folder, exist_ok=True)\n",
    "os.makedirs(save_gt_folder, exist_ok=True)\n",
    "os.makedirs(save_roi_folder, exist_ok=True)\n",
    "\n",
    "seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/evals/final_MRA_bin802_mul806_skr-bindice_nomir_5folds_val-best/without_pp'   #with_pp or without_pp\n",
    "# seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/evals/final_CTA_bin809_mul806_skr-bindice_nomir_5folds_val-best/with_pp'   #with_pp or without_pp\n",
    "# seg_folder = '/home/hasna/miccai24_challenges/topcow_challenge/evals/final_CROWN-MRA_bin802_mul808_skr-bindice_nomir_5folds_val-best/bin' #'/home/hasna/miccai24_challenges/topcow_challenge/evals/CTA-only_bin809_mul815_skr-bindice_nomir_5folds_val-best/without_pp'\n",
    "gt_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/cow_seg_labelsTr'  #'/home/hasna/datasets/TopCoW2024_Data_Release/CROWN23/mul_labelsTr'\n",
    "roi_folder = '/home/hasna/datasets/TopCoW2024_Data_Release/roi_loc_labelsTr'  #'/home/hasna/datasets/TopCoW2024_Data_Release/CROWN23/roi_size_loc'\n",
    "nfolds = 5\n",
    "\n",
    "for i in range(nfolds):\n",
    "    for file in tqdm(natsorted(os.listdir(os.path.join(seg_folder, f'fold_{i}')))):  # FIXME: for 5 folds\n",
    "        if file.startswith('topcow_mr_'):  # FIXME: For TopCoW\n",
    "        # if file.startswith('crown_'):  # FIXME: For CROWN\n",
    "            init_name = os.path.join(seg_folder, f'fold_{i}', file)  # FIXME: for 5 folds\n",
    "            new_name = os.path.join(pred_folder, file)\n",
    "            img = nib.load(init_name)\n",
    "            arr = img.get_fdata()\n",
    "            arr[arr == 13] = 15\n",
    "            nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(gt_folder, file)\n",
    "            ## img = nib.load(init_name)\n",
    "            ## arr = 1*(img.get_fdata() > 0)\n",
    "            new_name = os.path.join(save_gt_folder, file)\n",
    "            ## nib.save(nib.Nifti1Image(arr, img.affine), new_name)\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "            init_name = os.path.join(roi_folder, file.split('.')[0]+'.txt')\n",
    "            new_name = os.path.join(save_roi_folder, file.split('.')[0]+'.txt')\n",
    "            # init_name = os.path.join(roi_folder, 'crown_mr_roi_'+(file.split('.')[0]).split('_')[-1]+'.txt')\n",
    "            # new_name = os.path.join(save_roi_folder, 'crown_mr_roi_'+(file.split('.')[0]).split('_')[-1]+'.txt')\n",
    "            # shutil.copy(init_name, new_name)\n",
    "\n",
    "'''\n",
    "REPLACE NUMBERS IN HERE: \n",
    "/home/hasna/miccai24_challenges/TopCoW_Eval_Metrics/topcow24_eval/configs.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 777.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "main_dir = '/home/hasna/miccai24_challenges/topcow_challenge/nnunet_dir/dataset/preprocessed/Dataset815_TopCoWSegCTA/nnUNetPlans_3d_fullres'\n",
    "for file in tqdm(natsorted(os.listdir(main_dir))):\n",
    "    if file.endswith('.npy'):\n",
    "        # os.remove(os.path.join(main_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  6.18it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "main_dir = '/home/hasna/miccai24_challenges/feta_challenge/nnunet_dir/results_multiclass_new'\n",
    "for subdir in tqdm(natsorted(os.listdir(main_dir))):\n",
    "    if subdir.startswith('Dataset'):\n",
    "        for ssubd in natsorted(os.listdir(os.path.join(main_dir, subdir))):\n",
    "            if os.path.exists(os.path.join(main_dir, subdir, ssubd, 'masks')):\n",
    "                for file in natsorted(os.listdir(os.path.join(main_dir, subdir, ssubd, 'masks'))):\n",
    "                    if not file.startswith('feta_t2w_sub_008_') and not file.startswith('feta_t2w_mial_sub_008_') and not file.startswith('feta_t2w_lr_sub_008_'):\n",
    "                        # os.remove(os.path.join(main_dir, subdir, ssubd, 'masks', file))\n",
    "\n",
    "            if os.path.exists(os.path.join(main_dir, subdir, ssubd, 'preds')):\n",
    "                for file in natsorted(os.listdir(os.path.join(main_dir, subdir, ssubd, 'preds'))):\n",
    "                    if not file.startswith('feta_t2w_sub_008_') and not file.startswith('feta_t2w_mial_sub_008_') and not file.startswith('feta_t2w_lr_sub_008_'):\n",
    "                        # os.remove(os.path.join(main_dir, subdir, ssubd, 'preds', file))\n",
    "            else:\n",
    "                for file in natsorted(os.listdir(os.path.join(main_dir, subdir, ssubd))):\n",
    "                    if not file.startswith('feta_t2w_sub_008_') and not file.startswith('feta_t2w_mial_sub_008_') and not file.startswith('feta_t2w_lr_sub_008_'):\n",
    "                        # os.remove(os.path.join(main_dir, subdir, ssubd, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 167.04it/s]\n"
     ]
    }
   ],
   "source": [
    "main_dir = '/home/hasna/miccai24_challenges/feta_challenge/nnunet_dir/datasetnnUNet_trained_models/Dataset302_FETABaselineAll'\n",
    "for subdir in tqdm(os.listdir(main_dir)):\n",
    "    for fold in os.listdir(os.path.join(main_dir, subdir)):\n",
    "        if fold.startswith('fold_'):\n",
    "            if os.path.exists(os.path.join(main_dir, subdir, fold, 'validation')):\n",
    "                for file in os.listdir(os.path.join(main_dir, subdir, fold, 'validation')):\n",
    "                    if file.endswith('.nii.gz'):\n",
    "                        # os.remove(os.path.join(main_dir, subdir, fold, 'validation', file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet_epvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
